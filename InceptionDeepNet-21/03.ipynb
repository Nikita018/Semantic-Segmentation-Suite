{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionDeepNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPo/G2/kNlLBa/yUpIGW2a6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikita018/Semantic-Segmentation-Suite/blob/master/InceptionDeepNet-21/03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfBTFj07MID2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6e08e60-4354-4fd4-b796-2a37fedd05d6"
      },
      "source": [
        "# mouting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZd3Nxqbj2sF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62bb37b5-5989-4f82-e848-1bc7adb99c86"
      },
      "source": [
        "cd '/content/gdrive/My Drive/UBDS_college_work/SelfDrivingProject/Code/Semantic-Segmentation-Suite'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/UBDS_college_work/SelfDrivingProject/Code/Semantic-Segmentation-Suite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqJsndksMRk3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "966190e2-f262-4b59-e921-5863c4e7c165"
      },
      "source": [
        "import os, csv, random, time, datetime, cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from utils import utils,helpers\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9dAHUGONfEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdufHm_MKXMZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "dd37f732-b9f6-49d1-995d-d1df44c86abf"
      },
      "source": [
        "files=os.listdir(os.getcwd())\n",
        "print(files[0])\n",
        "img=cv2.imread(files[0])\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0001TP_006690_L.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAD8CAYAAAARze3ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSZFxDl1MBFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_label_info(csv_path):\n",
        "    \"\"\"\n",
        "    Retrieve the class names and label values for the selected dataset.\n",
        "    Must be in CSV format!\n",
        "    # Arguments\n",
        "        csv_path: The file path of the class dictionairy\n",
        "        \n",
        "    # Returns\n",
        "        Two lists: one for the class names and the other for the label values\n",
        "    \"\"\"\n",
        "    filename, file_extension = os.path.splitext(csv_path)\n",
        "    if not file_extension == \".csv\":\n",
        "        return ValueError(\"File is not a CSV!\")\n",
        "\n",
        "    class_names = []\n",
        "    label_values = []\n",
        "    with open(csv_path, 'r') as csvfile:\n",
        "        file_reader = csv.reader(csvfile, delimiter=',')\n",
        "        header = next(file_reader)\n",
        "        for row in file_reader:\n",
        "            class_names.append(row[0])\n",
        "            label_values.append([int(row[1]), int(row[2]), int(row[3])])\n",
        "        # print(class_dict)\n",
        "    return class_names, label_values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF9tXmkAvtr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the names of the classes so we can record the evaluation results\n",
        "class_names_list, label_values = get_label_info(os.path.join('/content/gdrive/My Drive/UBDS_college_work/SelfDrivingProject/Code/Semantic-Segmentation-Suite/CamVid/class_dict.csv'))\n",
        "class_names_string = \"\"\n",
        "for class_name in class_names_list:\n",
        "    if not class_name == class_names_list[-1]:\n",
        "        class_names_string = class_names_string + class_name + \", \"\n",
        "    else:\n",
        "        class_names_string = class_names_string + class_name\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBmIh-S9i5tN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_dir=\"CamVid\"\n",
        "\n",
        "def prepare_data(dataset_dir):\n",
        "    train_input_names=[]\n",
        "    train_output_names=[]\n",
        "    val_input_names=[]\n",
        "    val_output_names=[]\n",
        "    test_input_names=[]\n",
        "    test_output_names=[]\n",
        "    for file in os.listdir(dataset_dir + \"/train\"):\n",
        "        cwd = os.getcwd()\n",
        "        train_input_names.append(cwd + \"/\" + dataset_dir + \"/train/\" + file)\n",
        "    for file in os.listdir(dataset_dir + \"/train_labels\"):\n",
        "        cwd = os.getcwd()\n",
        "        train_output_names.append(cwd + \"/\" + dataset_dir + \"/train_labels/\" + file)\n",
        "    for file in os.listdir(dataset_dir + \"/val\"):\n",
        "        cwd = os.getcwd()\n",
        "        val_input_names.append(cwd + \"/\" + dataset_dir + \"/val/\" + file)\n",
        "    for file in os.listdir(dataset_dir + \"/val_labels\"):\n",
        "        cwd = os.getcwd()\n",
        "        val_output_names.append(cwd + \"/\" + dataset_dir + \"/val_labels/\" + file)\n",
        "    for file in os.listdir(dataset_dir + \"/test\"):\n",
        "        cwd = os.getcwd()\n",
        "        test_input_names.append(cwd + \"/\" + dataset_dir + \"/test/\" + file)\n",
        "    for file in os.listdir(dataset_dir + \"/test_labels\"):\n",
        "        cwd = os.getcwd()\n",
        "        test_output_names.append(cwd + \"/\" + dataset_dir + \"/test_labels/\" + file)\n",
        "    train_input_names.sort(),train_output_names.sort(), val_input_names.sort(), val_output_names.sort(), test_input_names.sort(), test_output_names.sort()\n",
        "    return train_input_names,train_output_names, val_input_names, val_output_names, test_input_names, test_output_names\n",
        "\n",
        "train_input_names,train_output_names, val_input_names, val_output_names, test_input_names, test_output_names = prepare_data(dataset_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwZT2rWTiv6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_image_batch = []\n",
        "output_image_batch = []\n",
        "batch_size=10\n",
        "i=1\n",
        "id_list = np.random.permutation(len(train_input_names))\n",
        "# Collect a batch of images\n",
        "for j in range(batch_size):\n",
        "    index = i*batch_size + j\n",
        "    id = id_list[index]\n",
        "    input_image = utils.load_image(train_input_names[id])\n",
        "    output_image = utils.load_image(train_output_names[id])\n",
        "\n",
        "    with tf.device('/cpu:0'):\n",
        "        input_image = np.float32(input_image) / 255.0\n",
        "        output_image = np.float32(helpers.one_hot_it(label=output_image, label_values=label_values))\n",
        "\n",
        "        input_image_batch.append(np.expand_dims(input_image, axis=0))\n",
        "        output_image_batch.append(np.expand_dims(output_image, axis=0))\n",
        "\n",
        "if batch_size == 1:\n",
        "    input_image_batch = input_image_batch[0]\n",
        "    output_image_batch = output_image_batch[0]\n",
        "else:\n",
        "    input_image_batch = np.squeeze(np.stack(input_image_batch, axis=1))\n",
        "    output_image_batch = np.squeeze(np.stack(output_image_batch, axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29Ike74nVe8F",
        "colab_type": "code",
        "outputId": "13393576-d5d2-4d23-f707-cb1c9c9fe149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (720, 960, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "print(last_output)\n",
        "inputs = last_output\n",
        "feature_map_size = tf.shape(last_output)\n",
        "depth=256\n",
        "label_size = tf.shape(inputs)[1:3]\n",
        "\n",
        "num_classes = 32\n",
        "\n",
        "# Global average pooling\n",
        "image_features = tf.reduce_mean(inputs, [1, 2], keep_dims=True)\n",
        "print(image_features)\n",
        "\n",
        "\n",
        "image_features = tf.keras.layers.Conv2D(\n",
        "    depth, [1, 1], strides=(1, 1), activity_regularizer=None\n",
        ")(image_features)\n",
        "\n",
        "image_features = tf.image.resize_bilinear(image_features, (feature_map_size[1], feature_map_size[2]))\n",
        "\n",
        "atrous_pool_block_1 = tf.keras.layers.Conv2D(depth, [1, 1], strides=(1, 1), activity_regularizer=None)(inputs)\n",
        "\n",
        "atrous_pool_block_6 = tf.keras.layers.Conv2D(depth, [3, 3], padding = 'same', dilation_rate = [6,6],activity_regularizer=None)(inputs)\n",
        "\n",
        "atrous_pool_block_12 = tf.keras.layers.Conv2D(depth, [3, 3], padding = 'same', dilation_rate = [12,12],activity_regularizer=None)(inputs)\n",
        "\n",
        "atrous_pool_block_18 = tf.keras.layers.Conv2D(depth, [3, 3], padding = 'same', dilation_rate = [18,18],activity_regularizer=None)(inputs)\n",
        "\n",
        "net = tf.concat((image_features, atrous_pool_block_1, atrous_pool_block_6, atrous_pool_block_12, atrous_pool_block_18), axis=3)\n",
        "net = tf.keras.layers.Conv2D(depth, [1, 1], activity_regularizer=None)(net)\n",
        "net = tf.image.resize_bilinear(net, size=label_size)\n",
        "net = tf.keras.layers.Conv2D(num_classes, [1, 1], activity_regularizer=None)(net)\n",
        "model = Model( net)\n",
        "#model.summary() "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-21 19:39:43--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.128, 2607:f8b0:400c:c12::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   186MB/s    in 0.5s    \n",
            "\n",
            "2020-03-21 19:39:43 (186 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "last layer output shape:  (None, 43, 58, 768)\n",
            "Tensor(\"mixed7_3/concat:0\", shape=(?, 43, 58, 768), dtype=float32)\n",
            "Tensor(\"Mean_3:0\", shape=(?, 1, 1, 768), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGz_pCF3k2Wz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c99bede0-4a57-41e1-a6aa-6e4a566a009c"
      },
      "source": [
        "model.outputs"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'conv2d_100/BiasAdd:0' shape=(?, ?, ?, 32) dtype=float32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgZhFHT3XeSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "8dcfedff-65cc-4ef2-fe51-7d16e07547df"
      },
      "source": [
        "# Compute your softmax cross entropy loss\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "history = model.fit(\n",
        "      input_image_batch, output_image_batch,\n",
        "      steps_per_epoch=8,  \n",
        "      epochs=1,\n",
        "      verbose=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 8 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-6b4a8bb46222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       verbose=1)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mactual_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [10,720,960] vs. [10,43,58]\n\t [[{{node metrics_2/acc/Equal}}]]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9q_cpKwTyUb",
        "colab_type": "code",
        "outputId": "4e8ad916-4d60-4abb-b06e-739cf02b45fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import random\n",
        "print(\"\\n***** Begin training *****\")\n",
        "avg_loss_per_epoch = []\n",
        "avg_scores_per_epoch = []\n",
        "avg_iou_per_epoch = []\n",
        "\n",
        "# Which validation images do we want\n",
        "val_indices = []\n",
        "num_vals = min(20, len(val_input_names))\n",
        "\n",
        "# Set random seed to make sure models are validated on the same validation images.\n",
        "# So you can compare the results of different models more intuitively.\n",
        "random.seed(16)\n",
        "val_indices=random.sample(range(0,len(val_input_names)),num_vals)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "***** Begin training *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnA97AFSVGvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image(path):\n",
        "    image = cv2.cvtColor(cv2.imread(path,-1), cv2.COLOR_BGR2RGB)\n",
        "    return image\n",
        "\n",
        "def one_hot_it(label, label_values):\n",
        "    \"\"\"\n",
        "    Convert a segmentation image label array to one-hot format\n",
        "    by replacing each pixel value with a vector of length num_classes\n",
        "    # Arguments\n",
        "        label: The 2D array segmentation image label\n",
        "        label_values\n",
        "        \n",
        "    # Returns\n",
        "        A 2D array with the same width and hieght as the input, but\n",
        "        with a depth size of num_classes\n",
        "    \"\"\"\n",
        "    # st = time.time()\n",
        "    # w = label.shape[0]\n",
        "    # h = label.shape[1]\n",
        "    # num_classes = len(class_dict)\n",
        "    # x = np.zeros([w,h,num_classes])\n",
        "    # unique_labels = sortedlist((class_dict.values()))\n",
        "    # for i in range(0, w):\n",
        "    #     for j in range(0, h):\n",
        "    #         index = unique_labels.index(list(label[i][j][:]))\n",
        "    #         x[i,j,index]=1\n",
        "    # print(\"Time 1 = \", time.time() - st)\n",
        "\n",
        "    # st = time.time()\n",
        "    # https://stackoverflow.com/questions/46903885/map-rgb-semantic-maps-to-one-hot-encodings-and-vice-versa-in-tensorflow\n",
        "    # https://stackoverflow.com/questions/14859458/how-to-check-if-all-values-in-the-columns-of-a-numpy-matrix-are-the-same\n",
        "    semantic_map = []\n",
        "    for colour in label_values:\n",
        "        # colour_map = np.full((label.shape[0], label.shape[1], label.shape[2]), colour, dtype=int)\n",
        "        equality = np.equal(label, colour)\n",
        "        class_map = np.all(equality, axis = -1)\n",
        "        semantic_map.append(class_map)\n",
        "    semantic_map = np.stack(semantic_map, axis=-1)\n",
        "    # print(\"Time 2 = \", time.time() - st)\n",
        "\n",
        "    return semantic_map\n",
        "\n",
        "def LOG(X, f=None):\n",
        "    time_stamp = datetime.datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
        "    if not f:\n",
        "        print(time_stamp + \" \" + X)\n",
        "    else:\n",
        "        f.write(time_stamp + \" \" + X)\n",
        "\n",
        "def reverse_one_hot(image):\n",
        "    \"\"\"\n",
        "    Transform a 2D array in one-hot format (depth is num_classes),\n",
        "    to a 2D array with only 1 channel, where each pixel value is\n",
        "    the classified class key.\n",
        "    # Arguments\n",
        "        image: The one-hot format image \n",
        "        \n",
        "    # Returns\n",
        "        A 2D array with the same width and hieght as the input, but\n",
        "        with a depth size of 1, where each pixel value is the classified \n",
        "        class key.\n",
        "    \"\"\"\n",
        "    # w = image.shape[0]\n",
        "    # h = image.shape[1]\n",
        "    # x = np.zeros([w,h,1])\n",
        "\n",
        "    # for i in range(0, w):\n",
        "    #     for j in range(0, h):\n",
        "    #         index, value = max(enumerate(image[i, j, :]), key=operator.itemgetter(1))\n",
        "    #         x[i, j] = index\n",
        "\n",
        "    x = np.argmax(image, axis = -1)\n",
        "    return x\n",
        "\n",
        "def colour_code_segmentation(image, label_values):\n",
        "    \"\"\"\n",
        "    Given a 1-channel array of class keys, colour code the segmentation results.\n",
        "    # Arguments\n",
        "        image: single channel array where each value represents the class key.\n",
        "        label_values\n",
        "        \n",
        "    # Returns\n",
        "        Colour coded image for segmentation visualization\n",
        "    \"\"\"\n",
        "    \n",
        "    colour_codes = np.array(label_values)\n",
        "    x = colour_codes[image.astype(int)]\n",
        "\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPwIUdkzXHdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess=tf.Session(config=config)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZI3IUZXURWS",
        "colab_type": "code",
        "outputId": "39c1e961-1968-4a94-9204-84aa095ec609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "# Do the training here\n",
        "num_epochs = 2\n",
        "batch_size = 10\n",
        "for epoch in range(0, num_epochs):\n",
        "\n",
        "    current_losses = []\n",
        "\n",
        "    cnt=0\n",
        "\n",
        "    # Equivalent to shuffling\n",
        "    id_list = np.random.permutation(len(train_input_names))\n",
        "\n",
        "    num_iters = int(np.floor(len(id_list) / batch_size))\n",
        "    st = time.time()\n",
        "    epoch_st=time.time()\n",
        "    for i in range(num_iters):\n",
        "        # st=time.time()\n",
        "        input_image_batch = []\n",
        "        output_image_batch = []\n",
        "\n",
        "        # Collect a batch of images\n",
        "        for j in range(batch_size):\n",
        "            index = i*batch_size + j\n",
        "            id = id_list[index]\n",
        "            input_image = load_image(train_input_names[id])\n",
        "            output_image = load_image(train_output_names[id])\n",
        "\n",
        "            with tf.device('/cpu:0'):\n",
        "                #input_image, output_image = data_augmentation(input_image, output_image)\n",
        "\n",
        "\n",
        "                # Prep the data. Make sure the labels are in one-hot format\n",
        "                input_image = np.float32(input_image) / 255.0\n",
        "                output_image = np.float32(one_hot_it(label=output_image, label_values=label_values))\n",
        "\n",
        "                input_image_batch.append(np.expand_dims(input_image, axis=0))\n",
        "                output_image_batch.append(np.expand_dims(output_image, axis=0))\n",
        "\n",
        "        if batch_size == 1:\n",
        "            input_image_batch = input_image_batch[0]\n",
        "            output_image_batch = output_image_batch[0]\n",
        "        else:\n",
        "            input_image_batch = np.squeeze(np.stack(input_image_batch, axis=1))\n",
        "            output_image_batch = np.squeeze(np.stack(output_image_batch, axis=1))\n",
        "\n",
        "        # Do the training\n",
        "        _,current=sess.run([opt,loss],feed_dict={net_input:input_image_batch,net_output:output_image_batch})\n",
        "        current_losses.append(current)\n",
        "        cnt = cnt + batch_size\n",
        "        if cnt % 20 == 0:\n",
        "            string_print = \"Epoch = %d Count = %d Current_Loss = %.4f Time = %.2f\"%(epoch,cnt,current,time.time()-st)\n",
        "            LOG(string_print)\n",
        "            st = time.time()\n",
        "\n",
        "    mean_loss = np.mean(current_losses)\n",
        "    avg_loss_per_epoch.append(mean_loss)\n",
        "\n",
        "    # Create directories if needed\n",
        "    if not os.path.isdir(\"%s/%04d\"%(\"checkpoints\",epoch)):\n",
        "        os.makedirs(\"%s/%04d\"%(\"checkpoints\",epoch))\n",
        "\n",
        "    # Save latest checkpoint to same file name\n",
        "    print(\"Saving latest checkpoint\")\n",
        "    saver.save(sess,model_checkpoint_name)\n",
        "\n",
        "    checkpoint_step = 5\n",
        "    validation_step = 1\n",
        "\n",
        "    if val_indices != 0 and epoch % checkpoint_step == 0:\n",
        "        print(\"Saving checkpoint for this epoch\")\n",
        "        saver.save(sess,\"%s/%04d/model.ckpt\"%(\"checkpoints\",epoch))\n",
        "\n",
        "\n",
        "    if epoch % validation_step == 0:\n",
        "        print(\"Performing validation\")\n",
        "        target=open(\"%s/%04d/val_scores.csv\"%(\"checkpoints\",epoch),'w')\n",
        "        target.write(\"val_name, avg_accuracy, precision, recall, f1 score, mean iou, %s\\n\" % (class_names_string))\n",
        "\n",
        "\n",
        "        scores_list = []\n",
        "        class_scores_list = []\n",
        "        precision_list = []\n",
        "        recall_list = []\n",
        "        f1_list = []\n",
        "        iou_list = []\n",
        "\n",
        "\n",
        "        # Do the validation on a small set of validation images\n",
        "        for ind in val_indices:\n",
        "\n",
        "            # input_image = np.expand_dims(np.float32(utils.load_image(val_input_names[ind])[:args.crop_height, :args.crop_width]),axis=0)/255.0\n",
        "            # gt = utils.load_image(val_output_names[ind])[:args.crop_height, :args.crop_width]\n",
        "            gt = reverse_one_hot(one_hot_it(gt, label_values))\n",
        "\n",
        "            # st = time.time()\n",
        "\n",
        "            output_image = sess.run(network,feed_dict={net_input:input_image})\n",
        "\n",
        "\n",
        "            output_image = np.array(output_image[0,:,:,:])\n",
        "            output_image = reverse_one_hot(output_image)\n",
        "            out_vis_image = colour_code_segmentation(output_image, label_values)\n",
        "\n",
        "            accuracy, class_accuracies, prec, rec, f1, iou = utils.evaluate_segmentation(pred=output_image, label=gt, num_classes=num_classes)\n",
        "\n",
        "            file_name = utils.filepath_to_name(val_input_names[ind])\n",
        "            target.write(\"%s, %f, %f, %f, %f, %f\"%(file_name, accuracy, prec, rec, f1, iou))\n",
        "            for item in class_accuracies:\n",
        "                target.write(\", %f\"%(item))\n",
        "            target.write(\"\\n\")\n",
        "\n",
        "            scores_list.append(accuracy)\n",
        "            class_scores_list.append(class_accuracies)\n",
        "            precision_list.append(prec)\n",
        "            recall_list.append(rec)\n",
        "            f1_list.append(f1)\n",
        "            iou_list.append(iou)\n",
        "\n",
        "            gt = helpers.colour_code_segmentation(gt, label_values)\n",
        "\n",
        "            file_name = os.path.basename(val_input_names[ind])\n",
        "            file_name = os.path.splitext(file_name)[0]\n",
        "            cv2.imwrite(\"%s/%04d/%s_pred.png\"%(\"checkpoints\",epoch, file_name),cv2.cvtColor(np.uint8(out_vis_image), cv2.COLOR_RGB2BGR))\n",
        "            cv2.imwrite(\"%s/%04d/%s_gt.png\"%(\"checkpoints\",epoch, file_name),cv2.cvtColor(np.uint8(gt), cv2.COLOR_RGB2BGR))\n",
        "\n",
        "\n",
        "        target.close()\n",
        "\n",
        "        avg_score = np.mean(scores_list)\n",
        "        class_avg_scores = np.mean(class_scores_list, axis=0)\n",
        "        avg_scores_per_epoch.append(avg_score)\n",
        "        avg_precision = np.mean(precision_list)\n",
        "        avg_recall = np.mean(recall_list)\n",
        "        avg_f1 = np.mean(f1_list)\n",
        "        avg_iou = np.mean(iou_list)\n",
        "        avg_iou_per_epoch.append(avg_iou)\n",
        "\n",
        "        print(\"\\nAverage validation accuracy for epoch # %04d = %f\"% (epoch, avg_score))\n",
        "        print(\"Average per class validation accuracies for epoch # %04d:\"% (epoch))\n",
        "        for index, item in enumerate(class_avg_scores):\n",
        "            print(\"%s = %f\" % (class_names_list[index], item))\n",
        "        print(\"Validation precision = \", avg_precision)\n",
        "        print(\"Validation recall = \", avg_recall)\n",
        "        print(\"Validation F1 score = \", avg_f1)\n",
        "        print(\"Validation IoU score = \", avg_iou)\n",
        "\n",
        "    epoch_time=time.time()-epoch_st\n",
        "    remain_time=epoch_time*(num_epochs-1-epoch)\n",
        "    m, s = divmod(remain_time, 60)\n",
        "    h, m = divmod(m, 60)\n",
        "    if s!=0:\n",
        "        train_time=\"Remaining training time = %d hours %d minutes %d seconds\\n\"%(h,m,s)\n",
        "    else:\n",
        "        train_time=\"Remaining training time : Training completed.\\n\"\n",
        "    LOG(train_time)\n",
        "    scores_list = []\n",
        "\n",
        "\n",
        "    fig1, ax1 = plt.subplots(figsize=(11, 8))\n",
        "\n",
        "    ax1.plot(range(epoch+1), avg_scores_per_epoch)\n",
        "    ax1.set_title(\"Average validation accuracy vs epochs\")\n",
        "    ax1.set_xlabel(\"Epoch\")\n",
        "    ax1.set_ylabel(\"Avg. val. accuracy\")\n",
        "\n",
        "\n",
        "    plt.savefig('accuracy_vs_epochs.png')\n",
        "\n",
        "    plt.clf()\n",
        "\n",
        "    fig2, ax2 = plt.subplots(figsize=(11, 8))\n",
        "\n",
        "    ax2.plot(range(epoch+1), avg_loss_per_epoch)\n",
        "    ax2.set_title(\"Average loss vs epochs\")\n",
        "    ax2.set_xlabel(\"Epoch\")\n",
        "    ax2.set_ylabel(\"Current loss\")\n",
        "\n",
        "    plt.savefig('loss_vs_epochs.png')\n",
        "\n",
        "    plt.clf()\n",
        "\n",
        "    fig3, ax3 = plt.subplots(figsize=(11, 8))\n",
        "\n",
        "    ax3.plot(range(epoch+1), avg_iou_per_epoch)\n",
        "    ax3.set_title(\"Average IoU vs epochs\")\n",
        "    ax3.set_xlabel(\"Epoch\")\n",
        "    ax3.set_ylabel(\"Current IoU\")\n",
        "\n",
        "    plt.savefig('iou_vs_epochs.png')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-181202d06522>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Do the training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mnet_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput_image_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moutput_image_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mcurrent_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'opt' is not defined"
          ]
        }
      ]
    }
  ]
}